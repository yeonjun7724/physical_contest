import streamlit as st
import cv2
import numpy as np
import base64
import requests
import json
from PIL import Image
import io
import time

# -----------------------------------------------------
# OpenAI Vision API í˜¸ì¶œ (429/Timeout ë°©ì§€ ë²„ì „)
# -----------------------------------------------------
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
OPENAI_URL = "https://api.openai.com/v1/chat/completions"
MODEL_NAME = "gpt-4o-mini"

def encode_frame(frame):
    img = Image.fromarray(frame)
    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=60)
    return base64.b64encode(buf.getvalue()).decode()


def call_openai_vision(messages, retries=6, delay=4):
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "max_tokens": 1400,
        "temperature": 0.2
    }

    for i in range(retries):
        try:
            res = requests.post(OPENAI_URL, headers=headers, json=payload, timeout=15)
            if res.status_code == 200:
                return res.json()["choices"][0]["message"]["content"]
            elif res.status_code == 429:
                time.sleep(delay)
            else:
                time.sleep(delay)
        except Exception:
            time.sleep(delay)

    raise RuntimeError("âš  OpenAI API ì˜¤ë¥˜: ì—¬ëŸ¬ ë²ˆ ì¬ì‹œë„í–ˆì§€ë§Œ ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")


# -----------------------------------------------------
# í”„ë ˆì„ ì¶”ì¶œ (3ê°œ)
# -----------------------------------------------------
def extract_frames(video_bytes):
    video = np.frombuffer(video_bytes, np.uint8)
    cap = cv2.VideoCapture(cv2.imdecode(video, cv2.IMREAD_COLOR))

    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    idxs = [int(total * 0.2), int(total * 0.5), int(total * 0.8)]
    frames = []

    for idx in idxs:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame)

    cap.release()
    return frames


# -----------------------------------------------------
# VLM ë¶„ì„ íŒŒì´í”„ë¼ì¸
# -----------------------------------------------------
def analyze_exercise(frames):
    images_payload = []

    for f in frames:
        b64 = encode_frame(f)
        images_payload.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{b64}"}
        })

    system_prompt = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ êµ­ë¯¼ì²´ë ¥100 ê³µì‹ ê¸°ì¤€ì„ ì˜ ì•„ëŠ” AI ì½”ì¹˜ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì˜ìƒì˜ í”„ë ˆì„ì„ ë³´ê³  ì–´ë–¤ ìš´ë™ì¸ì§€ ë¶„ë¥˜í•˜ê³ ,
ë™ì‘ì˜ ì •í™•ë„, ë°˜ë³µìˆ˜ ì¶”ì •, ì½”ì¹­ í¬ì¸íŠ¸, êµ­ë¯¼ì²´ë ¥100 ê¸°ì¤€ ì ìˆ˜/ë“±ê¸‰ì„ ì¶œë ¥í•˜ì„¸ìš”.

ì§€ì› ìš´ë™ ëª©ë¡:
- ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°(Sit-up)
- íŒ”êµ½í˜€í´ê¸°(Push-up)
- ìŠ¤ì¿¼íŠ¸(Squat)
- í”Œë­í¬(Plank)
- ë²„í”¼(Burpee)
- ëŸ°ì§€(Lunge)
- ì œìë¦¬ ì í”„ / ìŠ¤í…ë°•ìŠ¤ ì í”„
- ì˜¤ë˜ë‹¬ë¦¬ê¸°(ë™ì‘ íŒ¨í„´ ë³´ê³  ê°€ëŠ¥í•œ ê²½ìš° ì„¤ëª…)
- ê¸°íƒ€ ë³µí•© ìš´ë™: ê°€ì¥ ê°€ê¹Œìš´ ìš´ë™ìœ¼ë¡œ ë¶„ë¥˜

ì¶œë ¥ í˜•ì‹(JSON ONLY):
{
  "exercise_type": "",
  "rep_count_estimated": "",
  "form_quality": "",
  "coach_feedback": "",
  "kfta_score_estimated": "",
  "kfta_grade": ""
}
"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": images_payload}
    ]

    result = call_openai_vision(messages)
    return json.loads(result)


# -----------------------------------------------------
# Streamlit UI
# -----------------------------------------------------
st.set_page_config(
    page_title="AI êµ­ë¯¼ì²´ë ¥100 ìš´ë™ ë¶„ì„",
    layout="wide"
)

st.title("ğŸ’ª AI ê¸°ë°˜ êµ­ë¯¼ì²´ë ¥100 ìš´ë™ ë¶„ì„ê¸° (Demo)")
st.write("ì˜ìƒì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ ìš´ë™ ì¢…ë¥˜ë¥¼ ì¸ì‹í•˜ê³ , ìì„¸Â·ë°˜ë³µìˆ˜Â·ì ìˆ˜Â·ì½”ì¹­ì„ ì œê³µí•©ë‹ˆë‹¤.")

video = st.file_uploader("ğŸ¥ ìš´ë™ ì˜ìƒ ì—…ë¡œë“œ (mp4)", type=["mp4"])

if video is not None:
    st.video(video)

    if st.button("ğŸ” ìš´ë™ ë¶„ì„ ì‹¤í–‰"):
        video_bytes = video.read()

        with st.spinner("ğŸ¬ ì˜ìƒì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            frames = extract_frames(video_bytes)

        st.write("### ğŸ“¸ ì¶”ì¶œëœ ì˜ìƒ í”„ë ˆì„")
        cols = st.columns(len(frames))
        for i, f in enumerate(frames):
            cols[i].image(f, caption=f"Frame {i+1}", use_column_width=True)

        with st.spinner("ğŸ¤– AIê°€ ìš´ë™ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            result = analyze_exercise(frames)

        st.success("ë¶„ì„ ì™„ë£Œ!")

        st.write("## ğŸ“ ë¶„ì„ ê²°ê³¼")
        st.json(result)

        st.write("## ğŸ… AI ìš”ì•½")
        st.metric("ìš´ë™ ìœ í˜•", result["exercise_type"])
        st.metric("ì˜ˆìƒ ë°˜ë³µìˆ˜", result["rep_count_estimated"])
        st.metric("ìì„¸ ì •í™•ë„", result["form_quality"])
        st.metric("ì˜ˆìƒ ì ìˆ˜", f"{result['kfta_score_estimated']} ì ")
        st.metric("ì˜ˆìƒ ë“±ê¸‰", result["kfta_grade"])

        st.write("## ğŸ“˜ AI ì½”ì¹˜ í”¼ë“œë°±")
        st.write(result["coach_feedback"])
