import streamlit as st
import cv2
import base64
import json
import numpy as np
from PIL import Image
from io import BytesIO
import requests

# ------------------------------------------------------------
# GPT-4o-mini Vision í˜¸ì¶œ í•¨ìˆ˜ (429 ë°©ì§€)
# ------------------------------------------------------------
def call_openai(messages):
    url = "https://api.openai.com/v1/chat/completions"

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {st.secrets['OPENAI_API_KEY']}"
    }

    payload = {
        "model": "gpt-4o-mini",
        "messages": messages,
        "max_tokens": 900
    }

    # --- ì¬ì‹œë„ ë¡œì§ (429 ë°©ì§€) ---
    for attempt in range(3):
        response = requests.post(url, headers=headers, json=payload)

        if response.status_code == 429:
            st.warning("API ì‚¬ìš©ëŸ‰ì´ ëª°ë ¤ ì¬ì‹œë„ ì¤‘ì…ë‹ˆë‹¤â€¦ (429 Too Many Requests)")
            import time
            time.sleep(3)
            continue

        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]

    raise RuntimeError("OpenAI APIê°€ 3íšŒ ì¬ì‹œë„ì—ë„ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ------------------------------------------------------------
# ì´ë¯¸ì§€(base64ë¡œ ë³€í™˜)
# ------------------------------------------------------------
def pil_to_base64(pil_img):
    buf = BytesIO()
    pil_img.save(buf, format="JPEG")
    return base64.b64encode(buf.getvalue()).decode()

# ------------------------------------------------------------
# ì˜ìƒ â†’ í”„ë ˆì„ nê°œ ì¶”ì¶œ
# ------------------------------------------------------------
def extract_frames(video_bytes, n_frames=4):
    np_video = np.frombuffer(video_bytes, np.uint8)
    cap = cv2.VideoCapture(cv2.imdecode(np_video, cv2.IMREAD_COLOR))

    frames = []
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    idx_list = np.linspace(0, frame_count - 1, n_frames).astype(int)

    for idx in idx_list:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if ret:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(frame)

    cap.release()
    return frames

# ------------------------------------------------------------
# í”„ë ˆì„ ê¸°ë°˜ ìš´ë™ ë¶„ì„
# ------------------------------------------------------------
def analyze_frames_with_vlm(frames):
    images_payload = []

    for img in frames:
        pil_img = Image.fromarray(img)
        b64 = pil_to_base64(pil_img)
        images_payload.append({
            "type": "image_url",
            "image_url": f"data:image/jpeg;base64,{b64}"
        })

    system_prompt = """
ë‹¹ì‹ ì€ AI ê¸°ë°˜ ì²´ë ¥ì¸¡ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì…ë ¥ëœ ì—¬ëŸ¬ ì´ë¯¸ì§€(í”„ë ˆì„)ë¥¼ ë³´ê³  ì–´ë–¤ ìš´ë™ì¸ì§€ íŒë‹¨í•˜ê³ ,
êµ­ë¯¼ì²´ë ¥100 ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”.

ì§€ì›í•´ì•¼ í•˜ëŠ” ìš´ë™ ì¢…ë¥˜:
- ìœ—ëª¸ì¼ìœ¼í‚¤ê¸° (Sit-up)
- íŒ”êµ½í˜€í´ê¸° (Push-up)
- ìŠ¤ì¿¼íŠ¸ (Squat)
- í”Œë­í¬ (Plank)
- ë²„í”¼ (Burpee)
- ëŸ°ì§€ (Lunge)
- ì œìë¦¬ ì í”„ / ìŠ¤í…ë°•ìŠ¤ ì í”„
- ì˜¤ë˜ë‹¬ë¦¬ê¸°(ì™•ë³µë‹¬ë¦¬ê¸°)
- ì¢…í•© ì²´ë ¥í…ŒìŠ¤íŠ¸ ë™ì‘

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€:
{
 "detected_exercise": "ìš´ë™ëª…",
 "explanation": "íŒë‹¨ ê·¼ê±°",
 "score": {
     "total_score": ìˆ«ì,
     "grade": "ë“±ê¸‰",
     "detail": "ì„¸ë¶€ ë‚´ìš©"
 }
}
"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": images_payload}
    ]

    result = call_openai(messages)
    return json.loads(result)

# ------------------------------------------------------------
# Streamlit UI
# ------------------------------------------------------------
def main():
    st.set_page_config(page_title="AI ì²´ë ¥ì¸¡ì • (VLM)", layout="wide")
    st.title("ğŸ’ª AI ê¸°ë°˜ êµ­ë¯¼ì²´ë ¥ 100 ìë™ ì¸¡ì •ê¸°")
    st.write("ì—…ë¡œë“œí•œ ì˜ìƒì—ì„œ ìë™ìœ¼ë¡œ ìš´ë™ ì¢…ë¥˜ë¥¼ ì¸ì‹í•˜ê³  ì ìˆ˜/ë“±ê¸‰ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    uploaded = st.file_uploader("ğŸ“¤ ìš´ë™ ì˜ìƒ ì—…ë¡œë“œ (mp4)", type=["mp4"])

    if not uploaded:
        st.info("ìš´ë™ ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return

    # ì˜ìƒ ì²˜ë¦¬
    video_bytes = uploaded.read()

    st.subheader("1) ì˜ìƒ í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°")
    frames = extract_frames(video_bytes, n_frames=4)

    cols = st.columns(4)
    for i, f in enumerate(frames):
        cols[i].image(f, caption=f"Frame {i+1}", use_container_width=True)

    st.subheader("2) AI ë¶„ì„ ê²°ê³¼")
    with st.spinner("ğŸ”¥ VLMì´ ìš´ë™ì„ ë¶„ì„í•˜ëŠ” ì¤‘â€¦"):
        result = analyze_frames_with_vlm(frames)

    # ê²°ê³¼ í‘œì‹œ
    st.success("ë¶„ì„ ì™„ë£Œ!")

    st.json(result)

    st.subheader("3) ìš”ì•½ ê²°ê³¼")
    st.metric("ê°ì§€ëœ ìš´ë™", result["detected_exercise"])
    st.metric("ì´ì ", f"{result['score']['total_score']}ì ")
    st.metric("ì˜ˆìƒ ë“±ê¸‰", result["score"]["grade"])

    st.write("### ì„¸ë¶€ ë¶„ì„ ë¦¬í¬íŠ¸")
    st.write(result["score"]["detail"])

# ------------------------------------------------------------
if __name__ == "__main__":
    main()
