# ============================================
# êµ­ë¯¼ì²´ë ¥100 AI VLM ì¢…í•© ë¶„ì„ ì‹œìŠ¤í…œ
# ì™„ì„±íŒ app.py
# ============================================

import cv2
import base64import os
import io
import json
import time
import tempfile
from typing import List, Dict, Any, Optional, Tuple

import cv2
import numpy as np
from PIL import Image
import requests
import streamlit as st

# ============================================================
# 1. êµ­ë¯¼ì²´ë ¥100 ì ìˆ˜ í…Œì´ë¸” (ì˜ˆì‹œ) â€“ ì‹¤ì œ í‘œë¡œ êµì²´ ê°€ëŠ¥í•˜ê²Œ ì„¤ê³„
# ============================================================

"""
ì‹¤ì œ êµ­ë¯¼ì²´ë ¥100 ê³µì‹ ì ìˆ˜í‘œë¥¼ ê·¸ëŒ€ë¡œ ì˜®ê²¨ì„œ ì•„ë˜ ë”•ì…”ë„ˆë¦¬ì— ë„£ìœ¼ë©´ ë¨.
í˜„ì¬ ìˆ«ìëŠ” "ì˜ˆì‹œ ê°’"ì´ë¯€ë¡œ, ë°˜ë“œì‹œ ê³µì‹ ìë£Œ ë³´ê³  ìˆ˜ì •í•´ì•¼ í•¨.

êµ¬ì¡°:
KFTA_SCORES[exercise_key][gender][age_group] = [
    (ê¸°ì¤€ê°’, ì ìˆ˜),
    (ê¸°ì¤€ê°’, ì ìˆ˜),
    ...
    (0, 0)
]

- exercise_key: "situp", "pushup", "plank", "shuttle_run" ë“±
- gender: "male", "female"
- age_group: "10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"
- situp/pushup ë“±: reps(íšŸìˆ˜) ê¸°ì¤€, plank: seconds(ì´ˆ), shuttle_run: ì™•ë³µ íšŸìˆ˜ ë“±
"""

KFTA_SCORES: Dict[str, Dict[str, Dict[str, List[Tuple[float, int]]]]] = {
    # ìœ—ëª¸ì¼ìœ¼í‚¤ê¸° (ì˜ˆì‹œ ê°’)
    "situp": {
        "male": {
            "10ëŒ€": [(55, 100), (50, 90), (45, 80), (40, 70), (35, 60), (30, 50), (25, 40), (20, 30), (15, 20), (10, 10), (0, 0)],
            "20ëŒ€": [(52, 100), (47, 90), (42, 80), (37, 70), (32, 60), (27, 50), (22, 40), (17, 30), (12, 20), (7, 10), (0, 0)],
            "30ëŒ€": [(48, 100), (43, 90), (38, 80), (33, 70), (28, 60), (23, 50), (18, 40), (13, 30), (8, 20), (4, 10), (0, 0)],
            "40ëŒ€": [(44, 100), (39, 90), (34, 80), (29, 70), (24, 60), (19, 50), (14, 40), (9, 30), (5, 20), (2, 10), (0, 0)],
            "50ëŒ€": [(40, 100), (35, 90), (30, 80), (25, 70), (20, 60), (15, 50), (10, 40), (7, 30), (4, 20), (2, 10), (0, 0)],
            "60ëŒ€ ì´ìƒ": [(35, 100), (30, 90), (25, 80), (20, 70), (15, 60), (10, 50), (7, 40), (4, 30), (2, 20), (1, 10), (0, 0)],
        },
        "female": {
            "10ëŒ€": [(50, 100), (45, 90), (40, 80), (35, 70), (30, 60), (25, 50), (20, 40), (15, 30), (10, 20), (5, 10), (0, 0)],
            "20ëŒ€": [(45, 100), (40, 90), (35, 80), (30, 70), (25, 60), (20, 50), (15, 40), (10, 30), (7, 20), (3, 10), (0, 0)],
            "30ëŒ€": [(40, 100), (35, 90), (30, 80), (25, 70), (20, 60), (15, 50), (10, 40), (7, 30), (4, 20), (2, 10), (0, 0)],
            "40ëŒ€": [(36, 100), (31, 90), (26, 80), (21, 70), (16, 60), (11, 50), (8, 40), (5, 30), (3, 20), (1, 10), (0, 0)],
            "50ëŒ€": [(32, 100), (27, 90), (22, 80), (17, 70), (12, 60), (9, 50), (6, 40), (4, 30), (2, 20), (1, 10), (0, 0)],
            "60ëŒ€ ì´ìƒ": [(28, 100), (23, 90), (18, 80), (13, 70), (9, 60), (6, 50), (4, 40), (2, 30), (1, 20), (0, 10), (0, 0)],
        },
    },
    # íŒ”êµ½í˜€í´ê¸° (ì˜ˆì‹œ ê°’)
    "pushup": {
        "male": {
            "10ëŒ€": [(45, 100), (40, 90), (35, 80), (30, 70), (25, 60), (20, 50), (15, 40), (10, 30), (5, 20), (2, 10), (0, 0)],
            "20ëŒ€": [(42, 100), (37, 90), (32, 80), (27, 70), (22, 60), (17, 50), (12, 40), (8, 30), (4, 20), (2, 10), (0, 0)],
            "30ëŒ€": [(38, 100), (33, 90), (28, 80), (23, 70), (18, 60), (13, 50), (9, 40), (5, 30), (3, 20), (1, 10), (0, 0)],
            "40ëŒ€": [(34, 100), (29, 90), (24, 80), (19, 70), (14, 60), (10, 50), (7, 40), (4, 30), (2, 20), (1, 10), (0, 0)],
            "50ëŒ€": [(30, 100), (25, 90), (20, 80), (15, 70), (11, 60), (8, 50), (5, 40), (3, 30), (2, 20), (1, 10), (0, 0)],
            "60ëŒ€ ì´ìƒ": [(26, 100), (21, 90), (16, 80), (12, 70), (9, 60), (6, 50), (4, 40), (2, 30), (1, 20), (0, 10), (0, 0)],
        },
        "female": {
            "10ëŒ€": [(35, 100), (30, 90), (25, 80), (20, 70), (16, 60), (12, 50), (8, 40), (5, 30), (3, 20), (1, 10), (0, 0)],
            "20ëŒ€": [(32, 100), (27, 90), (22, 80), (18, 70), (14, 60), (10, 50), (7, 40), (4, 30), (2, 20), (1, 10), (0, 0)],
            "30ëŒ€": [(28, 100), (23, 90), (18, 80), (14, 70), (11, 60), (8, 50), (5, 40), (3, 30), (2, 20), (1, 10), (0, 0)],
            "40ëŒ€": [(24, 100), (19, 90), (15, 80), (11, 70), (8, 60), (6, 50), (4, 40), (2, 30), (1, 20), (0, 10), (0, 0)],
            "50ëŒ€": [(20, 100), (16, 90), (12, 80), (9, 70), (7, 60), (5, 50), (3, 40), (2, 30), (1, 20), (0, 10), (0, 0)],
            "60ëŒ€ ì´ìƒ": [(16, 100), (13, 90), (10, 80), (7, 70), (5, 60), (3, 50), (2, 40), (1, 30), (0, 20), (0, 10), (0, 0)],
        },
    },
    # í”Œë­í¬ (ì´ˆ ë‹¨ìœ„, ì˜ˆì‹œ)
    "plank": {
        "male": {
            "10ëŒ€": [(180, 100), (150, 90), (120, 80), (90, 70), (60, 60), (45, 50), (30, 40), (20, 30), (10, 20), (5, 10), (0, 0)],
            "20ëŒ€": [(180, 100), (150, 90), (120, 80), (90, 70), (60, 60), (45, 50), (30, 40), (20, 30), (10, 20), (5, 10), (0, 0)],
            "30ëŒ€": [(150, 100), (130, 90), (110, 80), (90, 70), (70, 60), (50, 50), (35, 40), (25, 30), (15, 20), (5, 10), (0, 0)],
            "40ëŒ€": [(140, 100), (120, 90), (100, 80), (80, 70), (60, 60), (45, 50), (30, 40), (20, 30), (10, 20), (5, 10), (0, 0)],
            "50ëŒ€": [(120, 100), (100, 90), (80, 80), (60, 70), (45, 60), (30, 50), (20, 40), (10, 30), (5, 20), (3, 10), (0, 0)],
            "60ëŒ€ ì´ìƒ": [(100, 100), (80, 90), (60, 80), (45, 70), (30, 60), (20, 50), (10, 40), (5, 30), (3, 20), (1, 10), (0, 0)],
        },
        "female": {
            "10ëŒ€": [(150, 100), (130, 90), (110, 80), (90, 70), (70, 60), (50, 50), (35, 40), (25, 30), (15, 20), (5, 10), (0, 0)],
            "20ëŒ€": [(150, 100), (130, 90), (110, 80), (90, 70), (70, 60), (50, 50), (35, 40), (25, 30), (15, 20), (5, 10), (0, 0)],
            "30ëŒ€": [(130, 100), (110, 90), (90, 80), (70, 70), (55, 60), (40, 50), (28, 40), (18, 30), (10, 20), (5, 10), (0, 0)],
            "40ëŒ€": [(110, 100), (90, 90), (75, 80), (60, 70), (45, 60), (30, 50), (20, 40), (12, 30), (7, 20), (3, 10), (0, 0)],
            "50ëŒ€": [(100, 100), (80, 90), (65, 80), (50, 70), (35, 60), (25, 50), (15, 40), (9, 30), (5, 20), (2, 10), (0, 0)],
            "60ëŒ€ ì´ìƒ": [(90, 100), (70, 90), (55, 80), (40, 70), (28, 60), (18, 50), (10, 40), (6, 30), (3, 20), (1, 10), (0, 0)],
        },
    },
    # ì™•ë³µ ì˜¤ë˜ë‹¬ë¦¬ê¸°ëŠ” ì¸¡ì • ë°©ì‹ì´ ë‹¤ì–‘í•´ì„œ ì—¬ê¸°ì„  ìƒëµ/ì˜ˆì‹œë§Œ
    "shuttle_run": {
        "male": {
            "10ëŒ€": [(60, 100), (55, 90), (50, 80), (45, 70), (40, 60), (35, 50), (30, 40), (25, 30), (20, 20), (15, 10), (0, 0)],
            "20ëŒ€": [(55, 100), (50, 90), (45, 80), (40, 70), (35, 60), (30, 50), (25, 40), (20, 30), (15, 20), (10, 10), (0, 0)],
            "30ëŒ€": [(50, 100), (45, 90), (40, 80), (35, 70), (30, 60), (25, 50), (20, 40), (15, 30), (10, 20), (5, 10), (0, 0)],
            "40ëŒ€": [(45, 100), (40, 90), (35, 80), (30, 70), (25, 60), (20, 50), (15, 40), (10, 30), (7, 20), (3, 10), (0, 0)],
            "50ëŒ€": [(40, 100), (35, 90), (30, 80), (25, 70), (20, 60), (15, 50), (10, 40), (7, 30), (4, 20), (2, 10), (0, 0)],
            "60ëŒ€ ì´ìƒ": [(35, 100), (30, 90), (25, 80), (20, 70), (15, 60), (10, 50), (7, 40), (4, 30), (2, 20), (1, 10), (0, 0)],
        },
        "female": {
            "10ëŒ€": [(50, 100), (45, 90), (40, 80), (35, 70), (30, 60), (25, 50), (20, 40), (15, 30), (10, 20), (5, 10), (0, 0)],
            "20ëŒ€": [(45, 100), (40, 90), (35, 80), (30, 70), (25, 60), (20, 50), (15, 40), (10, 30), (7, 20), (3, 10), (0, 0)],
            "30ëŒ€": [(40, 100), (35, 90), (30, 80), (25, 70), (20, 60), (15, 50), (10, 40), (7, 30), (4, 20), (2, 10), (0, 0)],
            "40ëŒ€": [(35, 100), (30, 90), (25, 80), (20, 70), (16, 60), (12, 50), (8, 40), (5, 30), (3, 20), (1, 10), (0, 0)],
            "50ëŒ€": [(30, 100), (25, 90), (20, 80), (16, 70), (12, 60), (9, 50), (6, 40), (4, 30), (2, 20), (1, 10), (0, 0)],
            "60ëŒ€ ì´ìƒ": [(25, 100), (20, 90), (16, 80), (12, 70), (9, 60), (6, 50), (4, 40), (2, 30), (1, 20), (0, 10), (0, 0)],
        },
    },
}

# burpee / squat / lunge / jump / mixed ëŠ” ê³µì‹ í•­ëª©ì´ ì•„ë‹ˆë¼
# "ì—°êµ¬ìš© ì ìˆ˜"ë¡œ ì²˜ë¦¬ (0~100 ì •ê·œí™”)ë§Œ í•´ ì¤„ ì˜ˆì •
NON_KFTA_EXERCISES = {"squat", "burpee", "lunge", "jump", "mixed"}


# ============================================================
# 2. OpenAI í˜¸ì¶œ ìœ í‹¸ (gpt-4o-mini + Vision, JSON ì¶œë ¥)
# ============================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
OPENAI_MODEL = "gpt-4o-mini"


def call_openai(messages: List[Dict[str, Any]], max_retries: int = 2) -> Optional[str]:
    """gpt-4o-miniì— Vision + JSON ìš”ì²­. ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (ì•± ì•ˆ ì£½ê²Œ)."""
    if not OPENAI_API_KEY:
        return None

    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": OPENAI_MODEL,
        "messages": messages,
        "response_format": {"type": "json_object"},
        "max_tokens": 1200,
    }

    for attempt in range(max_retries + 1):
        try:
            resp = requests.post(OPENAI_API_URL, headers=headers, json=payload, timeout=60)
            if resp.status_code == 429:
                # rate limit â†’ ì§§ê²Œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                wait = 3 * (attempt + 1)
                time.sleep(wait)
                continue
            resp.raise_for_status()
            data = resp.json()
            return data["choices"][0]["message"]["content"]
        except Exception:
            if attempt == max_retries:
                return None
            time.sleep(2 * (attempt + 1))
    return None


# ============================================================
# 3. ë¹„ë””ì˜¤ â†’ í”„ë ˆì„ ì¶”ì¶œ
# ============================================================

def extract_frames_from_video_bytes(
    video_bytes: bytes,
    num_frames: int = 8,
    resize_to: Tuple[int, int] = (640, 360),
) -> Tuple[List[np.ndarray], float]:
    """
    mp4 ë°”ì´íŠ¸ â†’ ì„ì‹œíŒŒì¼ â†’ OpenCVë¡œ í”„ë ˆì„ ê· ë“± ì¶”ì¶œ.
    return: (frames(RGB np.ndarray list), duration_sec)
    """
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
        tmp.write(video_bytes)
        tmp_path = tmp.name

    cap = cv2.VideoCapture(tmp_path)
    if not cap.isOpened():
        cap.release()
        os.remove(tmp_path)
        raise RuntimeError("ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS) or 0.000001
    duration_sec = frame_count / fps if frame_count > 0 else 0.0

    if frame_count <= 0:
        cap.release()
        os.remove(tmp_path)
        raise RuntimeError("ì˜ìƒì—ì„œ í”„ë ˆì„ ì •ë³´ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    idxs = np.linspace(0, frame_count - 1, num_frames, dtype=int)

    frames: List[np.ndarray] = []
    for idx in idxs:
        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))
        ret, frame = cap.read()
        if not ret:
            continue
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = cv2.resize(frame, resize_to)
        frames.append(frame)

    cap.release()
    os.remove(tmp_path)

    if not frames:
        raise RuntimeError("í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    return frames, float(duration_sec)


def pil_to_base64(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="JPEG")
    b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
    return f"data:image/jpeg;base64,{b64}"


import base64  # pil_to_base64ì—ì„œ ì‚¬ìš©


# ============================================================
# 4. í”„ë ˆì„ + í”„ë¡¬í”„íŠ¸ â†’ ìš´ë™ ë¶„ë¥˜ & ë¶„ì„ (gpt-4o-mini)
# ============================================================

EXERCISE_KEY_TO_NAME_KR = {
    "situp": "ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°",
    "pushup": "íŒ”êµ½í˜€í´ê¸°",
    "squat": "ìŠ¤ì¿¼íŠ¸",
    "plank": "í”Œë­í¬",
    "burpee": "ë²„í”¼",
    "lunge": "ëŸ°ì§€",
    "jump": "ì œìë¦¬ ì í”„/ìŠ¤í…ë°•ìŠ¤ ì í”„",
    "shuttle_run": "ì™•ë³µ ì˜¤ë˜ë‹¬ë¦¬ê¸°",
    "mixed": "ì¢…í•© ì²´ë ¥ ì¸¡ì •(í˜¼í•© ë™ì‘)",
}


def analyze_frames_with_vlm(frames: List[np.ndarray], duration_sec: float) -> Dict[str, Any]:
    """
    â‘  í”„ë ˆì„ë“¤ì„ JPEG â†’ base64ë¡œ ë³€í™˜
    â‘¡ gpt-4o-mini Vision ëª¨ë¸ì— JSON ìš”ì²­
    â‘¢ ìš´ë™ ë¶„ë¥˜ + ë°˜ë³µìˆ˜ ì¶”ì • + ìì„¸/ìœ„í—˜ìš”ì¸ ë¶„ì„
    """
    images_payload = []
    for f in frames:
        img = Image.fromarray(f)
        b64 = pil_to_base64(img)
        images_payload.append(
            {
                "type": "image_url",
                "image_url": {"url": b64},
            }
        )

    system_prompt = """
ë‹¹ì‹ ì€ ëŒ€í•œì²´ìœ¡íšŒ êµ­ë¯¼ì²´ë ¥100 ì¢…ëª© í‰ê°€ë¥¼ ë•ëŠ” AI ì½”ì¹˜ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì—¬ëŸ¬ ì¥ì˜ í”„ë ˆì„(ìš´ë™ ì˜ìƒì—ì„œ ì¶”ì¶œëœ ì´ë¯¸ì§€)ì„ ë³´ê³  ë‹¤ìŒ ìš´ë™ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

ê°€ëŠ¥í•œ ìš´ë™ ì¢…ë¥˜:
- situp: ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°
- pushup: íŒ”êµ½í˜€í´ê¸°
- squat: ìŠ¤ì¿¼íŠ¸
- plank: í”Œë­í¬
- burpee: ë²„í”¼ í…ŒìŠ¤íŠ¸/ë²„í”¼ ìš´ë™
- lunge: ëŸ°ì§€(ì•/ë’¤/ì›Œí‚¹ í¬í•¨)
- jump: ì œìë¦¬ ì í”„ ë˜ëŠ” ìŠ¤í…ë°•ìŠ¤ ì í”„
- shuttle_run: ì™•ë³µ ì˜¤ë˜ë‹¬ë¦¬ê¸°(ì™•ë³µ ë‹¬ë¦¬ê¸°, beep test ê³„ì—´)
- mixed: ì—¬ëŸ¬ ë™ì‘ì´ ì„ì—¬ ìˆì–´ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê¸° ì–´ë ¤ìš´ ê²½ìš°

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.

{
  "exercise_key": "situp | pushup | squat | plank | burpee | lunge | jump | shuttle_run | mixed",
  "exercise_name_kr": "í•œê¸€ ìš´ë™ ì´ë¦„",
  "estimated_reps": ì •ìˆ˜ (í”Œë­í¬/ì™•ë³µë‹¬ë¦¬ê¸° ë“±ë„ 'ë°˜ë³µìˆ˜' ë˜ëŠ” 'ì™•ë³µ ìˆ˜'ë¡œ ëŒ€ëµ ì¶”ì •),
  "estimated_main_metric": {
    "type": "reps | seconds | shuttles",
    "value": ìˆ«ì
  },
  "posture_quality": "poor | fair | good | excellent",
  "intensity": "low | moderate | high",
  "stability": "low | medium | high",
  "risk_flags": [
    "í—ˆë¦¬ ê³¼ì‹ ì „",
    "ë¬´ë¦ ì•ˆìª½ ëª¨ì„(ë‚´ë°˜/ì™¸ë°˜)",
    "ëª© ê¸´ì¥",
    "ì½”ì–´ ë¶ˆì•ˆì •",
    "ì†ëª© ê³¼ì‚¬ìš©",
    "í˜¸í¡ ë¶ˆê·œì¹™"
  ] ì¤‘ í•´ë‹¹í•˜ëŠ” ê²ƒë§Œ ì„ íƒ (ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´),
  "coach_comment": "ì§§ì€ í•œê¸€ ì„¤ëª…ìœ¼ë¡œ ìš´ë™ íŠ¹ì§•, ìì„¸ í”¼ë“œë°±, ì£¼ì˜ì  ë“±ì„ ì„œìˆ "
}
"""

    user_prompt = f"""
ì•„ë˜ ì´ë¯¸ì§€ëŠ” í•˜ë‚˜ì˜ ìš´ë™ ì˜ìƒì„ {len(frames)}ê°œ í”„ë ˆì„ìœ¼ë¡œ ë½‘ì€ ê²ƒì…ë‹ˆë‹¤.
ì‹¤ì œ ì˜ìƒ ê¸¸ì´ëŠ” ì•½ {duration_sec:.1f}ì´ˆ ì…ë‹ˆë‹¤.

- ì˜ìƒì—ì„œ ì–´ë–¤ ìš´ë™ì„ í•˜ëŠ”ì§€ ìœ„ì˜ exercise_key ì¤‘ í•˜ë‚˜ë¡œ ì„ íƒ
- ë°˜ë³µìˆ˜, ì™•ë³µ ìˆ˜, ë²„í‹´ ì‹œê°„ ë“±ì€ "í”„ë ˆì„ë§Œ ë³´ê³  ìµœëŒ€í•œ í•©ë¦¬ì ìœ¼ë¡œ ì¶”ì •"í•˜ì„¸ìš”.
- êµ­ë¯¼ì²´ë ¥100 ê³µì‹ ì¢…ëª©(ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°, íŒ”êµ½í˜€í´ê¸°, ì˜¤ë˜ë‹¬ë¦¬ê¸° ë“±)ê³¼ ìœ ì‚¬í•œ í˜•íƒœë¼ë©´ ê·¸ì— ë§ê²Œ ë¶„ë¥˜
- JSON ì´ì™¸ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.
"""

    messages = [
        {"role": "system", "content": system_prompt.strip()},
        {
            "role": "user",
            "content": [
                {"type": "text", "text": user_prompt.strip()},
                *images_payload,
            ],
        },
    ]

    raw = call_openai(messages)
    if raw is None:
        raise RuntimeError("AI ë¶„ì„ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (API Key, ë„¤íŠ¸ì›Œí¬, rate limit í™•ì¸ í•„ìš”)")

    try:
        data = json.loads(raw)
    except json.JSONDecodeError:
        raise RuntimeError("AI ì‘ë‹µì„ JSONìœ¼ë¡œ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ê¸°ë³¸ê°’ ë³´ì •
    exercise_key = data.get("exercise_key", "mixed")
    if exercise_key not in EXERCISE_KEY_TO_NAME_KR:
        exercise_key = "mixed"
    data["exercise_key"] = exercise_key
    data.setdefault("exercise_name_kr", EXERCISE_KEY_TO_NAME_KR[exercise_key])
    data.setdefault("estimated_reps", 0)
    data.setdefault("estimated_main_metric", {"type": "reps", "value": data.get("estimated_reps", 0)})
    data.setdefault("posture_quality", "fair")
    data.setdefault("intensity", "moderate")
    data.setdefault("stability", "medium")
    data.setdefault("risk_flags", [])
    data.setdefault("coach_comment", "")

    # ì‹¤ì œ ì˜ìƒ ê¸¸ì´ë„ í•¨ê»˜ ë°˜í™˜ (ì ìˆ˜ ê³„ì‚° ë“±ì— ì‚¬ìš© ê°€ëŠ¥)
    data["video_duration_sec"] = duration_sec

    return data


# ============================================================
# 5. êµ­ë¯¼ì²´ë ¥100 ì ìˆ˜ ê³„ì‚° ë¡œì§
# ============================================================

def lookup_kfta_score(
    exercise_key: str,
    gender: str,
    age_group: str,
    value: float,
) -> Tuple[int, str, str, str]:
    """
    exercise_key, gender('ë‚¨ì„±'/'ì—¬ì„±'), age_group('20ëŒ€' ë“±), ì¸¡ì •ê°’(value)ì„ ê¸°ë°˜ìœ¼ë¡œ
    êµ­ë¯¼ì²´ë ¥100 ì ìˆ˜í‘œì—ì„œ ì ìˆ˜ ì°¾ê¸°.

    return: (score, grade, level_label, remark)
    """
    gender_key = "male" if gender == "ë‚¨ì„±" else "female"

    # KFTAì— ì—†ëŠ” ìš´ë™ì€ ì—°êµ¬ìš© ì ìˆ˜ë¡œ ì²˜ë¦¬
    if exercise_key in NON_KFTA_EXERCISES or exercise_key not in KFTA_SCORES:
        # 0~100 ì‚¬ì´ë¡œ ëŒ€ëµ ì •ê·œí™” (ì—°êµ¬ìš©) â€“ í•„ìš”ì‹œ ìˆ˜ì •
        # reps/seconds ê°’ì´ 0~ìµœëŒ€ ìƒí•œ(ì˜ˆ: 50) ì‚¬ì´ë¡œ ë“¤ì–´ì˜¨ë‹¤ê³  ê°€ì •
        max_ref = 50.0
        score = int(max(0, min(100, value / max_ref * 100)))
        # 5ë“±ê¸‰ ë¶„ë¥˜
        if score >= 90:
            grade, level = 1, "ë§¤ìš° ìš°ìˆ˜(ì—°êµ¬ìš©)"
        elif score >= 75:
            grade, level = 2, "ìš°ìˆ˜(ì—°êµ¬ìš©)"
        elif score >= 60:
            grade, level = 3, "ë³´í†µ(ì—°êµ¬ìš©)"
        elif score >= 45:
            grade, level = 4, "ì£¼ì˜ í•„ìš”(ì—°êµ¬ìš©)"
        else:
            grade, level = 5, "ê°œì„  í•„ìš”(ì—°êµ¬ìš©)"
        remark = "í•´ë‹¹ ìš´ë™ì€ êµ­ë¯¼ì²´ë ¥100 ê³µì‹ ê¸°ì¤€ì´ ì•„ë‹ˆë¯€ë¡œ ì—°êµ¬ìš© ì ìˆ˜ë¡œ ì‚°ì •í–ˆìŠµë‹ˆë‹¤."
        return score, grade, level, remark

    # ê³µì‹ KFTA í•­ëª©
    table_exc = KFTA_SCORES.get(exercise_key, {})
    table_gender = table_exc.get(gender_key, {})
    thresholds = table_gender.get(age_group, [])

    if not thresholds:
        # ë‚˜ì´Â·ì„±ë³„ ì¡°í•©ì´ í…Œì´ë¸”ì— ì—†ì„ ë•Œ
        return 0, 0, "ì ìˆ˜í‘œ ì—†ìŒ", "í•´ë‹¹ ì—°ë ¹/ì„±ë³„ ì¡°í•©ì˜ êµ­ë¯¼ì²´ë ¥100 ê¸°ì¤€í‘œê°€ ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."

    # thresholds: [(value_min, score), ...] ìˆœì„œëŒ€ë¡œ ì²« ë²ˆì§¸ë¡œ ë§Œì¡±í•˜ëŠ” ì ìˆ˜ ì‚¬ìš©
    score = 0
    for v_min, sc in thresholds:
        if value >= v_min:
            score = sc
            break

    # ì ìˆ˜ â†’ ë“±ê¸‰
    if score >= 90:
        grade, level = 1, "ë§¤ìš° ìš°ìˆ˜"
    elif score >= 75:
        grade, level = 2, "ìš°ìˆ˜"
    elif score >= 60:
        grade, level = 3, "ë³´í†µ"
    elif score >= 45:
        grade, level = 4, "ì£¼ì˜ í•„ìš”"
    else:
        grade, level = 5, "ê°œì„  í•„ìš”"

    remark = "ì ìˆ˜ëŠ” ì˜ˆì‹œ ê°’ì…ë‹ˆë‹¤. ì‹¤ì œ êµ­ë¯¼ì²´ë ¥100 ê³µì‹ ê¸°ì¤€ê°’ìœ¼ë¡œ êµì²´í•´ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."
    return score, grade, level, remark


def compute_score_from_analysis(
    analysis: Dict[str, Any],
    age_group: str,
    gender: str,
) -> Dict[str, Any]:
    """
    VLM ë¶„ì„ ê²°ê³¼ + ì—°ë ¹/ì„±ë³„ ì…ë ¥ â†’ êµ­ë¯¼ì²´ë ¥100 ì ìˆ˜ ê³„ì‚°.
    """
    exercise_key = analysis.get("exercise_key", "mixed")
    metric = analysis.get("estimated_main_metric", {})
    metric_type = metric.get("type", "reps")
    metric_value = float(metric.get("value", analysis.get("estimated_reps", 0)))

    # í”Œë­í¬ëŠ” seconds, ì™•ë³µ ë‹¬ë¦¬ê¸°ëŠ” shuttles ì‚¬ìš©
    if exercise_key == "plank":
        metric_type = "seconds"
        metric_value = max(metric_value, analysis.get("video_duration_sec", 0.0))
    elif exercise_key == "shuttle_run":
        metric_type = "shuttles"

    score, grade, level, remark = lookup_kfta_score(
        exercise_key=exercise_key,
        gender=gender,
        age_group=age_group,
        value=metric_value,
    )

    return {
        "exercise_key": exercise_key,
        "exercise_name_kr": EXERCISE_KEY_TO_NAME_KR.get(exercise_key, "ì•Œ ìˆ˜ ì—†ìŒ"),
        "metric_type": metric_type,
        "metric_value": metric_value,
        "score": score,
        "grade": grade,
        "level_label": level,
        "remark": remark,
    }


# ============================================================
# 6. Streamlit UI
# ============================================================

def main():
    st.set_page_config(page_title="êµ­ë¯¼ì²´ë ¥100 VLM ìë™ ë¶„ì„ ë°ëª¨", layout="wide")

    st.title("ğŸƒâ€â™‚ï¸ AI ê¸°ë°˜ êµ­ë¯¼ì²´ë ¥100 ì˜ìƒ ë¶„ì„ ë°ëª¨")
    st.markdown(
        """
ì—…ë¡œë“œí•œ **ìš´ë™ ì˜ìƒ(mp4)**ì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ê³ ,  
**gpt-4o-mini Vision**ì„ ì´ìš©í•´ ìš´ë™ ì¢…ë¥˜ë¥¼ ë¶„ë¥˜í•˜ê³  êµ­ë¯¼ì²´ë ¥100 ê¸°ì¤€ì— ë§ì¶° ì ìˆ˜ë¥¼ ì¶”ì •í•˜ëŠ” ë°ëª¨ì…ë‹ˆë‹¤.

- ì§€ì› ìš´ë™:
  - ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°, íŒ”êµ½í˜€í´ê¸°, ìŠ¤ì¿¼íŠ¸, í”Œë­í¬, ë²„í”¼, ëŸ°ì§€, ì œìë¦¬ ì í”„/ìŠ¤í…ë°•ìŠ¤ ì í”„, ì™•ë³µ ì˜¤ë˜ë‹¬ë¦¬ê¸°, ì¢…í•© ì²´ë ¥ ì¸¡ì •(í˜¼í•©)
- VLMì€ **í”„ë ˆì„ ê¸°ë°˜ ì¶”ì •**ì´ë¯€ë¡œ ë°˜ë³µìˆ˜Â·ì ìˆ˜ëŠ” ì‹¤ì œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì ìˆ˜í‘œ ìˆ«ìëŠ” **ì˜ˆì‹œ**ì´ë©°, ì‹¤ì œ êµ­ë¯¼ì²´ë ¥100 ê³µì‹ ê¸°ì¤€ê°’ìœ¼ë¡œ êµì²´í•  ìˆ˜ ìˆë„ë¡ êµ¬ì¡°ë§Œ ë§ì¶° ë‘ì—ˆìŠµë‹ˆë‹¤.
"""
    )

    # ì‚¬ì´ë“œë°”: OpenAI ìƒíƒœ
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        if OPENAI_API_KEY:
            st.success("OpenAI API Key ê°ì§€ë¨ âœ…")
        else:
            st.error("OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\nStreamlit Secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— `OPENAI_API_KEY`ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
        st.markdown("---")
        st.markdown("**ëª¨ë¸**: `gpt-4o-mini` (Vision + JSON)")

    # ì…ë ¥ í¼
    col_left, col_right = st.columns([1, 2])

    with col_left:
        st.subheader("1ï¸âƒ£ ê¸°ë³¸ ì •ë³´")

        age_group = st.selectbox(
            "ì—°ë ¹ëŒ€",
            ["20ëŒ€", "10ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"],
            index=1,
            help="êµ­ë¯¼ì²´ë ¥100 ê¸°ì¤€ê³¼ ì—°ë™ë  ì—°ë ¹ëŒ€ì…ë‹ˆë‹¤.",
        )
        gender = st.selectbox(
            "ì„±ë³„",
            ["ë‚¨ì„±", "ì—¬ì„±"],
            index=0,
        )

        st.subheader("2ï¸âƒ£ ì˜ìƒ ì—…ë¡œë“œ")
        video_file = st.file_uploader(
            "ìš´ë™ ì˜ìƒ ì—…ë¡œë“œ (mp4 í˜•ì‹)",
            type=["mp4"],
            accept_multiple_files=False,
            help="êµ­ë¯¼ì²´ë ¥100 ì¸¡ì • ì˜ìƒì„ ì´¬ì˜í•œ mp4 íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.",
        )

        analyze_button = st.button("ğŸ” ì˜ìƒ ë¶„ì„ ì‹œì‘", type="primary")

    with col_right:
        st.subheader("3ï¸âƒ£ ì—…ë¡œë“œëœ ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°")
        if video_file is not None:
            st.video(video_file)
        else:
            st.info("ì™¼ìª½ì—ì„œ mp4 íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ì—¬ê¸°ì—ì„œ ë¯¸ë¦¬ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # ë¶„ì„ ì‹¤í–‰
    if analyze_button:
        if video_file is None:
            st.error("ë¨¼ì € mp4 ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()

        # â‘  ë°”ì´íŠ¸ ì½ê¸°
        video_bytes = video_file.getvalue()

        # â‘¡ í”„ë ˆì„ ì¶”ì¶œ
        try:
            with st.spinner("ğŸ ì˜ìƒì—ì„œ ëŒ€í‘œ í”„ë ˆì„ ì¶”ì¶œ ì¤‘..."):
                frames, duration_sec = extract_frames_from_video_bytes(video_bytes, num_frames=8)
        except Exception as e:
            st.error(f"í”„ë ˆì„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.stop()

        st.success(f"í”„ë ˆì„ {len(frames)}ì¥ ì¶”ì¶œ ì™„ë£Œ (ì˜ìƒ ê¸¸ì´ ì•½ {duration_sec:.1f}ì´ˆ)")

        # í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°
        st.subheader("4ï¸âƒ£ ì¶”ì¶œëœ ëŒ€í‘œ í”„ë ˆì„")
        cols = st.columns(min(len(frames), 4))
        for i, frame in enumerate(frames):
            cols[i % len(cols)].image(frame, caption=f"Frame {i+1}", use_container_width=True)

        # â‘¢ AI ë¶„ì„
        try:
            with st.spinner("ğŸ¤– AI VLMì´ ìš´ë™ ì¢…ë¥˜ì™€ ìì„¸ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                analysis = analyze_frames_with_vlm(frames, duration_sec)
        except Exception as e:
            st.error(f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.stop()

        st.success("AI ë¶„ì„ ì™„ë£Œ!")

        # â‘£ êµ­ë¯¼ì²´ë ¥100 ì ìˆ˜ ê³„ì‚°
        score_result = compute_score_from_analysis(analysis, age_group=age_group, gender=gender)

        # â‘¤ ê²°ê³¼ í‘œì‹œ
        st.markdown("---")
        st.subheader("5ï¸âƒ£ AI ìš´ë™ ë¶„ë¥˜ ê²°ê³¼")

        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("ìš´ë™ ë¶„ë¥˜", f"{analysis['exercise_name_kr']} ({analysis['exercise_key']})")
        with c2:
            st.metric("ì¶”ì • ë°˜ë³µ/ê¸°ë¡",
                      f"{score_result['metric_value']:.1f} {score_result['metric_type']}")
        with c3:
            st.metric("ì˜ìƒ ê¸¸ì´", f"{analysis['video_duration_sec']:.1f} ì´ˆ")

        st.write("**ìì„¸/ê°•ë„ ë¶„ì„**")
        st.write(
            f"- ìì„¸ í’ˆì§ˆ: **{analysis['posture_quality']}**  "
            f"- ê°•ë„: **{analysis['intensity']}**  "
            f"- ì•ˆì •ì„±: **{analysis['stability']}**"
        )

        if analysis.get("risk_flags"):
            st.warning("âš ï¸ ìœ„í—˜ ìš”ì¸(ì¶”ì •): " + " / ".join(analysis["risk_flags"]))
        else:
            st.info("íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì¸ì´ í¬ê²Œ ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (VLM ì¶”ì •)")

        st.markdown("**AI ì½”ì¹˜ ì½”ë©˜íŠ¸**")
        st.write(analysis.get("coach_comment", ""))

        st.markdown("---")
        st.subheader("6ï¸âƒ£ êµ­ë¯¼ì²´ë ¥100 ê¸°ì¤€ ì ìˆ˜ (ì¶”ì •)")

        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("ì ìˆ˜ (0~100)", f"{score_result['score']} ì ")
        with c2:
            if score_result["grade"] > 0:
                st.metric("ë“±ê¸‰ (1~5)", f"{score_result['grade']} ë“±ê¸‰")
            else:
                st.metric("ë“±ê¸‰ (1~5)", "ê¸°ì¤€ ì—†ìŒ")
        with c3:
            st.metric("í‰ê°€", score_result["level_label"])

        st.caption(score_result["remark"])

        st.markdown("---")
        st.subheader("7ï¸âƒ£ ì›ë³¸ AI JSON ê²°ê³¼ (ë””ë²„ê¹…/ì—°êµ¬ìš©)")
        col_json1, col_json2 = st.columns(2)
        with col_json1:
            st.write("ğŸ” VLM ë¶„ì„ Raw JSON")
            st.json(analysis)
        with col_json2:
            st.write("ğŸ§® ì ìˆ˜ ê³„ì‚° ê²°ê³¼ JSON")
            st.json(score_result)


# ============================================================
# 7. ì‹¤í–‰
# ============================================================

if __name__ == "__main__":
    main()

import time
import json
import requests
import numpy as np
from io import BytesIO
from PIL import Image
import streamlit as st


# ============================================
# OpenAI í˜¸ì¶œ í•¨ìˆ˜ (429 ìë™ ì¬ì‹œë„)
# ============================================

def call_openai(messages, model="gpt-4o-mini", max_retries=5):
    api_key = st.secrets["OPENAI_API_KEY"]
    url = "https://api.openai.com/v1/chat/completions"

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": model,
        "messages": messages,
        "temperature": 0.2
    }

    for i in range(max_retries):
        response = requests.post(url, json=payload, headers=headers)

        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"]

        if response.status_code == 429:  # rate limit
            time.sleep(1.2)   # ë”œë ˆì´ í›„ ì¬ì‹œë„
            continue

        # ê¸°íƒ€ ì˜¤ë¥˜
        st.error(f"API ì˜¤ë¥˜: {response.text}")
        return None

    raise RuntimeError("OpenAI APIê°€ ì—¬ëŸ¬ ë²ˆ ì¬ì‹œë„í–ˆì§€ë§Œ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


# ============================================
# í”„ë ˆì„ ì¶”ì¶œ í•¨ìˆ˜ (8~12 í”„ë ˆì„)
# ============================================

def extract_frames(video_bytes, num_frames=10):
    """mp4 ë°”ì´íŠ¸ â†’ OpenCV ì˜ìƒ â†’ í”„ë ˆì„ ì¶”ì¶œ"""

    # ë°”ì´ë„ˆë¦¬ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    video_path = "temp_video.mp4"
    with open(video_path, "wb") as f:
        f.write(video_bytes)

    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        return []

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    idxs = np.linspace(0, frame_count - 1, num_frames).astype(int)

    frames = []
    for idx in idxs:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if not ret:
            continue

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = cv2.resize(frame, (512, 288))
        frames.append(frame)

    cap.release()
    return frames


# ============================================
# í”„ë ˆì„ â†’ base64 ì´ë¯¸ì§€ ë³€í™˜
# ============================================

def pil_to_b64(img):
    buf = BytesIO()
    img.save(buf, format="JPEG")
    return base64.b64encode(buf.getvalue()).decode()


# ============================================
# í”„ë ˆì„ ê¸°ë°˜ VLM ë¶„ì„
# ============================================

def analyze_frames(frames):
    """ìš´ë™ ë¶„ë¥˜ + ë°˜ë³µíšŸìˆ˜ ì¶”ì • + ìì„¸í‰ê°€"""

    images_payload = []

    # ì´ë¯¸ì§€ 10ê°œë¥¼ multi-modal ë©”ì‹œì§€ë¡œ êµ¬ì„±
    for f in frames:
        b64 = pil_to_b64(Image.fromarray(f))
        images_payload.append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{b64}"}
        })

    system_prompt = """
ë‹¹ì‹ ì€ êµ­ë¯¼ì²´ë ¥100 ì „ë¬¸ê°€ì´ì Vision-Language ëª¨ë¸ì…ë‹ˆë‹¤.
10ì¥ì˜ í”„ë ˆì„ì„ ë³´ê³  ë‹¤ìŒ í•­ëª©ì„ JSON ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.

{
 "exercise_type": "situp | pushup | squat | plank | burpee | lunge | jump | shuttle_run | unknown",
 "estimated_reps": ìˆ«ì,
 "posture_score": 0~40,
 "tempo": "slow | steady | fast",
 "stability": "low | medium | high",
 "risk_flags": ["ë¬´ë¦ í”ë“¤ë¦¼", "í—ˆë¦¬ êµ½í˜", ...]
}
"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": images_payload}
    ]

    result = call_openai(messages)
    return json.loads(result)


# ============================================
# êµ­ë¯¼ì²´ë ¥100 ì ìˆ˜ ê³„ì‚°
# ============================================

def score_kfta(exercise_type, reps, posture_score):
    """ìš´ë™ë³„ ê¸°ì¤€ ì ìˆ˜ ê³„ì‚°"""

    # ------------------------------
    # êµ­ë¯¼ì²´ë ¥100 ê°„ì´ ì ìˆ˜í‘œ (ì„ì‹œ)
    # ------------------------------
    table = {
        "situp": 30,
        "pushup": 40,
        "squat": 40,
        "burpee": 30,
        "lunge": 30,
        "jump": 50,
        "shuttle_run": 40,
    }

    if exercise_type not in table:
        return 0, 5

    max_reps = table[exercise_type]

    performance_score = min(reps / max_reps * 60, 60)
    total = int(min(performance_score + posture_score, 100))

    if total >= 90: grade = 1
    elif total >= 75: grade = 2
    elif total >= 60: grade = 3
    elif total >= 45: grade = 4
    else: grade = 5

    return total, grade


# ============================================
# Streamlit UI
# ============================================

def main():
    st.set_page_config(page_title="êµ­ë¯¼ì²´ë ¥100 AI ë¶„ì„", layout="wide")
    st.title("ğŸ‹ï¸â€â™‚ï¸ êµ­ë¯¼ì²´ë ¥100 AI ìš´ë™ ë¶„ì„ê¸° (GPT-4o-mini Vision)")

    st.markdown("mp4 ì˜ìƒì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ **ìš´ë™ ì¢…ë¥˜, ë°˜ë³µ íšŸìˆ˜, ìì„¸ í‰ê°€, êµ­ë¯¼ì²´ë ¥100 ì ìˆ˜**ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

    video = st.file_uploader("ìš´ë™ ì˜ìƒ ì—…ë¡œë“œ (mp4)", type=["mp4"])

    if video:
        video_bytes = video.read()

        st.subheader("ğŸ“¸ 1) ì˜ìƒì—ì„œ ëŒ€í‘œ í”„ë ˆì„ ì¶”ì¶œ")
        frames = extract_frames(video_bytes)

        if len(frames) == 0:
            st.error("í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨. ë‹¤ë¥¸ ì˜ìƒìœ¼ë¡œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            st.stop()

        cols = st.columns(min(len(frames), 5))
        for i, f in enumerate(frames[:5]):
            cols[i].image(f, caption=f"Frame {i+1}", use_container_width=True)

        st.subheader("ğŸ¤– 2) AI VLM ë¶„ì„ ì¤‘â€¦")
        with st.spinner("GPT-4o-miniê°€ ì˜ìƒ ë¶„ì„ ì¤‘â€¦"):
            result = analyze_frames(frames)

        st.json(result)

        # êµ­ë¯¼ì²´ë ¥100 ì ìˆ˜ ê³„ì‚°
        exercise_type = result["exercise_type"]
        reps = result["estimated_reps"]
        posture_score = result["posture_score"]

        kfta_score, grade = score_kfta(exercise_type, reps, posture_score)

        st.subheader("ğŸ… 3) êµ­ë¯¼ì²´ë ¥100 ìë™ ì ìˆ˜ ì‚°ì¶œ")
        st.metric("ì´ì ", f"{kfta_score}/100")
        st.metric("ì˜ˆìƒë“±ê¸‰", f"{grade} ë“±ê¸‰")

        st.success("ë¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
