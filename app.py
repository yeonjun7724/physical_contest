import os
import io
import cv2
import base64
import json
import time
import tempfile
import numpy as np
from PIL import Image
import streamlit as st
from openai import OpenAI

# ------------------------------
# OpenAI Client (í™˜ê²½ë³€ìˆ˜ ìë™ ì¸ì‹)
# ------------------------------
# ê¸°ì¡´: client = OpenAI(api_key=OPENAI_API_KEY)
client = OpenAI()   # â† THIS FIXES THE ERROR

# ------------------------------
# êµ­ë¯¼ì²´ë ¥ ì •ë³´ (ì˜ˆì‹œê°’ ê·¸ëŒ€ë¡œ)
# ------------------------------
KFTA_SCORES = {
    "situp": {
        "male": {
            "20ëŒ€": [(52, 100), (47, 90), (42, 80), (37, 70), (32, 60), (27, 50), (22, 40), (17, 30), (12, 20), (7, 10), (0, 0)]
        },
        "female": {
            "20ëŒ€": [(45, 100), (40, 90), (35, 80), (30, 70), (25, 60), (20, 50), (15, 40), (10, 30), (7, 20), (3, 10), (0, 0)]
        },
    },
    "pushup": {
        "male": {
            "20ëŒ€": [(42, 100), (37, 90), (32, 80), (27, 70), (22, 60), (17, 50), (12, 40), (8, 30), (4, 20), (2, 10), (0, 0)]
        },
        "female": {
            "20ëŒ€": [(32, 100), (27, 90), (22, 80), (18, 70), (14, 60), (10, 50), (7, 40), (4, 30), (2, 20), (1, 10), (0, 0)]
        },
    },
}

EXERCISE_NAMES = {
    "situp": "ìœ—ëª¸ì¼ìœ¼í‚¤ê¸°",
    "pushup": "íŒ”êµ½í˜€í´ê¸°",
    "squat": "ìŠ¤ì¿¼íŠ¸",
    "plank": "í”Œë­í¬",
    "burpee": "ë²„í”¼",
    "lunge": "ëŸ°ì§€",
    "jump": "ì í”„",
    "shuttle_run": "ì™•ë³µ ì˜¤ë˜ë‹¬ë¦¬ê¸°",
    "mixed": "í˜¼í•© ë™ì‘",
}

NON_KFTA = {"squat", "lunge", "jump", "burpee", "mixed"}

# ------------------------------
# ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
# ------------------------------
def extract_frames(video_bytes, num_frames=4, resize=(640, 360)):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
        tmp.write(video_bytes)
        tmp_path = tmp.name

    cap = cv2.VideoCapture(tmp_path)

    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS) or 1
    duration = frame_count / fps

    idxs = np.linspace(0, frame_count - 1, num_frames).astype(int)

    frames = []
    for idx in idxs:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if not ret:
            continue
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = cv2.resize(frame, resize)
        frames.append(frame)

    cap.release()
    os.remove(tmp_path)

    return frames, duration


# ------------------------------
# í”„ë ˆì„ â†’ base64
# ------------------------------
def pil_to_b64(img):
    buf = io.BytesIO()
    img.save(buf, format="JPEG")
    b64 = base64.b64encode(buf.getvalue()).decode()
    return f"data:image/jpeg;base64,{b64}"


# ------------------------------
# OpenAI VLM ë¶„ì„
# ------------------------------
def analyze_frames(frames, duration):
    images_payload = [
        {"type": "input_image", "image_url": pil_to_b64(Image.fromarray(f))}
        for f in frames
    ]

    prompt = """
ë‹¹ì‹ ì€ ìš´ë™ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì˜ìƒì˜ í”„ë ˆì„ì„ ë³´ê³  ë‹¤ìŒ JSONì„ ë°˜í™˜í•˜ì„¸ìš”:

{
 "exercise_key": "...",
 "exercise_name_kr": "...",
 "estimated_reps": ìˆ«ì,
 "main_metric": {"type": "reps|seconds", "value": ìˆ«ì},
 "posture": "ì¢‹ìŒ|ë³´í†µ|ë‚˜ì¨",
 "risk": ["í•­ëª©1", "í•­ëª©2"]
}
"""

    result = client.responses.create(
        model="gpt-4o-mini",
        input=[
            {"role": "user", "content": [{"type": "text", "text": prompt}, *images_payload]}
        ]
    )

    parsed = client.responses.parse(result)
    return parsed.output[0]


# ------------------------------
# KFTA ì ìˆ˜ ê³„ì‚°
# ------------------------------
def calc_kfta(exercise_key, gender, age_group, value):
    gender_key = "male" if gender == "ë‚¨ì„±" else "female"

    if exercise_key in NON_KFTA or exercise_key not in KFTA_SCORES:
        score = min(100, int(value * 2))
        grade = 1 if score >= 90 else 2 if score >= 75 else 3 if score >= 60 else 4 if score >= 45 else 5
        return score, grade, "ì—°êµ¬ìš© í‰ê°€"

    table = KFTA_SCORES[exercise_key][gender_key][age_group]

    for threshold, sc in table:
        if value >= threshold:
            score = sc
            break

    grade = 1 if score >= 90 else 2 if score >= 75 else 3 if score >= 60 else 4 if score >= 45 else 5
    return score, grade, "êµ­ë¯¼ì²´ë ¥100 ê¸°ì¤€(ì˜ˆì‹œ)"


# ------------------------------
# Streamlit UI
# ------------------------------
st.set_page_config(page_title="AI êµ­ë¯¼ì²´ë ¥ ë¶„ì„", layout="wide")

st.title("ğŸƒ AI ê¸°ë°˜ êµ­ë¯¼ì²´ë ¥ ì˜ìƒ ë¶„ì„")

with st.sidebar:
    st.header("âš™ ì„¤ì •")
    age = st.selectbox("ì—°ë ¹ëŒ€", ["20ëŒ€"])
    gender = st.selectbox("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±"])

st.write("ì•„ë˜ì— ìš´ë™ ì˜ìƒì„ ì—…ë¡œë“œí•˜ë©´ ìë™ ë¶„ì„í•©ë‹ˆë‹¤.")

video_file = st.file_uploader("MP4 ì˜ìƒ ì—…ë¡œë“œ", type=["mp4"])

if st.button("ë¶„ì„ ì‹œì‘"):
    if not video_file:
        st.error("ë¨¼ì € ì˜ìƒì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        st.stop()

    with st.spinner("í”„ë ˆì„ ì¶”ì¶œ ì¤‘..."):
        frames, duration = extract_frames(video_file.read(), num_frames=4)

    with st.spinner("AI ë¶„ì„ ì¤‘..."):
        analysis = analyze_frames(frames, duration)

    st.success("AI ë¶„ì„ ì™„ë£Œ!")

    st.write("### ğŸ“Œ ìš´ë™ ë¶„ì„ ê²°ê³¼")
    st.json(analysis)

    key = analysis["exercise_key"]
    metric = analysis["main_metric"]["value"]

    score, grade, remark = calc_kfta(key, gender, age, metric)

    st.write("### ğŸ… êµ­ë¯¼ì²´ë ¥ ì ìˆ˜")
    st.metric("ì ìˆ˜", f"{score}ì ")
    st.metric("ë“±ê¸‰", f"{grade}ë“±ê¸‰")
    st.caption(remark)
