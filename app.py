import os
import cv2
import base64
import time
import json
import requests
import numpy as np
import streamlit as st
from PIL import Image


# ============================================================
# 0. OpenAI API í˜¸ì¶œ(429 ë°©ì§€ìš© ì¬ì‹œë„ í¬í•¨)
# ============================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

def call_openai(messages, max_retries=5):
    url = "https://api.openai.com/v1/chat/completions"

    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }

    payload = {
        "model": "gpt-4o-mini",
        "messages": messages,
        "max_tokens": 1800,
        "temperature": 0.2
    }

    for attempt in range(max_retries):
        response = requests.post(url, headers=headers, json=payload)

        if response.status_code == 429:
            wait = 2 * (attempt + 1)
            time.sleep(wait)
            continue

        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]

    raise RuntimeError("OpenAI 429 rate limit â€” ì¬ì‹œë„ ì‹¤íŒ¨")


# ============================================================
# 1. í”„ë ˆì„ ì¶”ì¶œ í•¨ìˆ˜ (4í”„ë ˆì„)
# ============================================================

def extract_frames(video_bytes, num_frames=4, size=(384, 384)):
    np_bytes = np.frombuffer(video_bytes, np.uint8)
    video = cv2.imdecode(np_bytes, cv2.IMREAD_COLOR)

    temp_path = "temp_input.mp4"
    with open(temp_path, "wb") as f:
        f.write(video_bytes)

    cap = cv2.VideoCapture(temp_path)
    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    idxs = np.linspace(0, total - 1, num_frames).astype(int)

    frames = []
    for i in idxs:
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if ret:
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame = cv2.resize(frame, size)
            frames.append(frame)

    cap.release()
    return frames


def pil_to_base64(img):
    buf = st.BytesIO()
    img.save(buf, format="JPEG")
    b64 = base64.b64encode(buf.getvalue()).decode()
    return f"data:image/jpeg;base64,{b64}"


# ============================================================
# 2. VLM ë¶„ë¥˜ + ìì„¸ ë¶„ì„
# ============================================================

def analyze_frames_with_vlm(frames):
    images_payload = []

    for img in frames:
        b64 = pil_to_base64(Image.fromarray(img))
        images_payload.append({"type": "image_url", "image_url": {"url": b64}})

    system_prompt = """
ë‹¹ì‹ ì€ í•œêµ­ êµ­ë¯¼ì²´ë ¥100 ì „ë¬¸ê°€ì´ë©°, ì˜ìƒ ì‚¬ì§„ì„ ê¸°ë°˜ìœ¼ë¡œ ìš´ë™ ì¢…ë¥˜ì™€ ìì„¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

ì¶œë ¥ì€ JSON í•˜ë‚˜ë§Œ!
{
 "exercise_type": "...",   // sit-up, push-up, squat, plank, burpee, lunge, shuttle_run, jump ë“±
 "key_points": "...",       // í•µì‹¬ ìì„¸ ì„¤ëª…
 "risk": "...",             // ë¶€ìƒ ê°€ëŠ¥ì„±
 "score_raw": 0-100         // ëŒ€ëµì  ìˆ˜í–‰ ìˆ˜ì¤€(ì¶”ì •)
}
"""

    user_prompt = "ì•„ë˜ í”„ë ˆì„ì„ ê¸°ë°˜ìœ¼ë¡œ ìš´ë™ ì¢…ë¥˜ì™€ ìˆ˜í–‰ ìƒíƒœë¥¼ ë¶„ì„í•˜ì„¸ìš”."

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": [{"type": "text", "text": user_prompt}] + images_payload}
    ]

    result = call_openai(messages)
    return json.loads(result)


# ============================================================
# 3. Streamlit UI
# ============================================================

def main():
    st.set_page_config(page_title="AI êµ­ë¯¼ì²´ë ¥100 ìë™ ë¶„ì„ê¸°", layout="centered")

    st.title("ğŸ‹ï¸ AI ì²´ë ¥ì¸¡ì • ìë™ ë¶„ì„ (VLM ê¸°ë°˜)")
    st.write("í•œêµ­ êµ­ë¯¼ì²´ë ¥100 ê¸°ì¤€ìœ¼ë¡œ ì˜ìƒ ì† ìš´ë™ì„ ìë™ ì¸ì‹í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.")

    video = st.file_uploader("ìš´ë™ ì˜ìƒ(mp4) ì—…ë¡œë“œ", type=["mp4"])

    if video is None:
        st.info("ìš´ë™ ì˜ìƒì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘í•˜ê¸°", type="primary"):
        video_bytes = video.read()

        st.subheader("1) ëŒ€í‘œ í”„ë ˆì„ ì¶”ì¶œ")
        frames = extract_frames(video_bytes)

        col = st.columns(len(frames))
        for i, f in enumerate(frames):
            col[i].image(f, caption=f"Frame {i+1}")

        with st.spinner("AIê°€ ìš´ë™ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤â€¦"):
            result = analyze_frames_with_vlm(frames)

        st.success("ë¶„ì„ ì™„ë£Œ!")

        st.subheader("2) ë¶„ì„ ê²°ê³¼ (JSON)")
        st.json(result)

        st.subheader("3) ìì—°ì–´ ìš”ì•½ ë¦¬í¬íŠ¸")
        st.write(f"""
### ğŸ” ìš´ë™ ë¶„ë¥˜  
- **ìš´ë™ ì¢…ë¥˜:** {result['exercise_type']}

### ğŸ‘ ì£¼ìš” í¬ì¸íŠ¸  
{result['key_points']}

### âš ï¸ ë¶€ìƒ ìœ„í—˜  
{result['risk']}

### â­ ìˆ˜í–‰ ì ìˆ˜ (ì¶”ì •)  
**{result['score_raw']} / 100**
        """)


# ============================================================
if __name__ == "__main__":
    if OPENAI_API_KEY is None:
        st.error("â— OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    main()
